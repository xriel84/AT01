[
  {
    "filename": "demo_conference_talk.mp4",
    "path": "C:/AT01/input/demo_conference_talk.mp4",
    "duration": 432.0,
    "resolution": "1920x1080",
    "codec": "h264",
    "source": "demo-scaffold",
    "whisper_segments": [
      {"start": 0.0, "end": 4.2, "text": "Welcome everyone to our presentation on AI-assisted video editing."},
      {"start": 4.5, "end": 9.8, "text": "Today we'll be looking at how machine learning can transform the post-production workflow."},
      {"start": 10.2, "end": 15.1, "text": "First, let me introduce our team and the tools we've been building."},
      {"start": 15.5, "end": 21.3, "text": "Over the past six months we developed an automated chapter detection system."},
      {"start": 21.8, "end": 27.0, "text": "It analyzes transcription data and silence patterns to find natural chapter boundaries."},
      {"start": 28.0, "end": 33.5, "text": "The system uses rule-based heuristics combined with gap analysis."},
      {"start": 34.0, "end": 39.2, "text": "Let me show you a quick demo of how the chapter detection works in practice."},
      {"start": 65.0, "end": 70.5, "text": "Now moving on to our second topic, the natural language command interface."},
      {"start": 71.0, "end": 76.8, "text": "Users can type commands like add chapter markers or color code speakers."},
      {"start": 77.2, "end": 83.0, "text": "The system translates these into structured edit decisions for DaVinci Resolve."},
      {"start": 83.5, "end": 89.0, "text": "We use template matching for common commands and an LLM fallback for complex ones."},
      {"start": 90.0, "end": 95.5, "text": "The dry-run mode lets you preview changes before they are applied."},
      {"start": 130.0, "end": 135.2, "text": "Our third area of focus has been the smart portrait cropping pipeline."},
      {"start": 135.8, "end": 141.0, "text": "It uses person detection and tracking to follow speakers in landscape footage."},
      {"start": 141.5, "end": 147.3, "text": "The output is a nine-by-sixteen portrait crop suitable for YouTube Shorts."},
      {"start": 148.0, "end": 153.5, "text": "Person tracking uses ultralytics YOLO for real-time bounding box detection."},
      {"start": 200.0, "end": 205.8, "text": "Let me now discuss integration with DaVinci Resolve Studio."},
      {"start": 206.2, "end": 212.0, "text": "We connect via the scripting API to create timelines, add markers, and set clip colors."},
      {"start": 212.5, "end": 218.3, "text": "The bridge serializes all operations through a queue because the API is not thread-safe."},
      {"start": 219.0, "end": 225.0, "text": "Currently we support six API capabilities that have been live-tested and confirmed."},
      {"start": 300.0, "end": 305.5, "text": "For the final section I want to talk about the library system."},
      {"start": 306.0, "end": 312.0, "text": "We scan directories of video files and extract metadata, transcripts, and chapters."},
      {"start": 312.5, "end": 318.2, "text": "The output is a JSON library file that feeds all of our viewer tools."},
      {"start": 319.0, "end": 325.0, "text": "Viewers can search transcripts, navigate chapters, and export timecodes."},
      {"start": 400.0, "end": 406.0, "text": "In conclusion, this pipeline transforms raw footage into searchable structured data."},
      {"start": 406.5, "end": 412.0, "text": "All processing runs locally on GPU with zero cloud dependencies."},
      {"start": 412.5, "end": 420.0, "text": "Thank you for your time. I'm happy to take any questions from the audience."},
      {"start": 420.5, "end": 432.0, "text": "We have about ten minutes for questions before we wrap up the session."}
    ]
  },
  {
    "filename": "demo_interview_segment.mp4",
    "path": "C:/AT01/input/demo_interview_segment.mp4",
    "duration": 295.0,
    "resolution": "1920x1080",
    "codec": "h264",
    "source": "demo-scaffold",
    "whisper_segments": [
      {"start": 0.0, "end": 5.5, "text": "So David, tell us about how the Christmas Carol project started."},
      {"start": 6.0, "end": 12.0, "text": "It began about four years ago when we first started exploring VR theater."},
      {"start": 12.5, "end": 18.0, "text": "The idea was to bring classic stories into an immersive virtual environment."},
      {"start": 19.0, "end": 25.0, "text": "We wanted to see if audiences would connect with Dickens in a VR space."},
      {"start": 60.0, "end": 66.0, "text": "The technical challenges were significant. We had to figure out motion capture."},
      {"start": 66.5, "end": 72.0, "text": "Each performer wore a tracking suit and we captured everything in real time."},
      {"start": 72.5, "end": 78.0, "text": "The live audience was actually in a physical theater watching the VR feed."},
      {"start": 130.0, "end": 136.5, "text": "The most rewarding part was seeing the audience reactions during live shows."},
      {"start": 137.0, "end": 143.0, "text": "People would gasp when Marley's ghost appeared because it felt so real."},
      {"start": 143.5, "end": 149.0, "text": "That emotional connection is what convinced us to keep developing the format."},
      {"start": 200.0, "end": 206.0, "text": "Looking forward, we want to expand to other classic productions."},
      {"start": 206.5, "end": 212.0, "text": "There is a lot of interest from educational institutions as well."},
      {"start": 212.5, "end": 218.0, "text": "Schools want to use VR theater to teach Shakespeare and other classics."},
      {"start": 270.0, "end": 276.0, "text": "I think the future of theater will include both physical and virtual spaces."},
      {"start": 276.5, "end": 282.0, "text": "They complement each other rather than competing."},
      {"start": 282.5, "end": 290.0, "text": "Thank you David, that was a fascinating conversation about VR theater."},
      {"start": 290.5, "end": 295.0, "text": "Thank you for having me. It's been great to share our journey."}
    ]
  },
  {
    "filename": "demo_stage_rehearsal.mov",
    "path": "C:/AT01/input/demo_stage_rehearsal.mov",
    "duration": 180.0,
    "resolution": "3840x2160",
    "codec": "prores",
    "source": "demo-scaffold",
    "whisper_segments": [
      {"start": 0.0, "end": 5.0, "text": "Okay let's run through the opening scene one more time."},
      {"start": 5.5, "end": 11.0, "text": "Scrooge enters from stage left, the ghost appears from above."},
      {"start": 12.0, "end": 17.5, "text": "Remember the timing on the lighting cue needs to be tighter this time."},
      {"start": 50.0, "end": 55.0, "text": "Marley's ghost I need you to hold that position for three more seconds."},
      {"start": 55.5, "end": 61.0, "text": "The VR camera needs time to capture the full reveal."},
      {"start": 62.0, "end": 68.0, "text": "Great. Now let's move to the Ghost of Christmas Past sequence."},
      {"start": 100.0, "end": 106.0, "text": "The transition between past and present needs work."},
      {"start": 106.5, "end": 112.0, "text": "We should add a particle effect during the scene change."},
      {"start": 112.5, "end": 118.0, "text": "The audience reported feeling disoriented during the last test."},
      {"start": 150.0, "end": 155.5, "text": "Final scene. Scrooge wakes up on Christmas morning."},
      {"start": 156.0, "end": 162.0, "text": "This is the emotional peak, so we need the music to swell here."},
      {"start": 162.5, "end": 170.0, "text": "Perfect. Let's take five and then do a full run-through."},
      {"start": 170.5, "end": 180.0, "text": "Everyone did great work today. We're getting close to show-ready."}
    ]
  },
  {
    "filename": "demo_behind_scenes.mp4",
    "path": "C:/AT01/input/demo_behind_scenes.mp4",
    "duration": 245.0,
    "resolution": "1920x1080",
    "codec": "h264",
    "source": "demo-scaffold",
    "whisper_segments": [
      {"start": 0.0, "end": 5.0, "text": "Welcome to the behind the scenes look at our production."},
      {"start": 5.5, "end": 11.0, "text": "This is where the motion capture magic happens."},
      {"start": 11.5, "end": 17.0, "text": "We have twelve cameras positioned around the performance space."},
      {"start": 60.0, "end": 66.0, "text": "The costume department has been working on period-accurate outfits."},
      {"start": 66.5, "end": 72.0, "text": "Each costume has tracking markers embedded in the fabric."},
      {"start": 72.5, "end": 78.0, "text": "This allows us to capture both the performer and the costume movement."},
      {"start": 120.0, "end": 126.0, "text": "Sound design is another critical component of the VR experience."},
      {"start": 126.5, "end": 132.0, "text": "We use spatial audio to place sounds in the virtual environment."},
      {"start": 132.5, "end": 138.0, "text": "When Scrooge walks past you can hear his footsteps shift position."},
      {"start": 180.0, "end": 186.0, "text": "Post-production involves combining all the captured data streams."},
      {"start": 186.5, "end": 192.0, "text": "We use DaVinci Resolve for color grading and final assembly."},
      {"start": 192.5, "end": 198.0, "text": "The AI tools help us detect chapters and organize the timeline."},
      {"start": 230.0, "end": 236.0, "text": "The entire workflow from capture to final export takes about two weeks."},
      {"start": 236.5, "end": 242.0, "text": "With the AI pipeline we have cut that down to about three days."},
      {"start": 242.5, "end": 245.0, "text": "And the quality keeps improving with each iteration."}
    ]
  }
]
